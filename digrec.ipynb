{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    cache = Z\n",
    "    A = 1./(1+np.exp(-Z))\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    cache = Z\n",
    "    A = np.maximum(0,Z)\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = pd.read_csv('train.csv').values.astype(np.float64)\n",
    "    labels = (np.reshape(data[:,0].astype(np.int64),(-1,1))).T\n",
    "    labels.shape\n",
    "    #labels = data[:,0].astype(np.int32)\n",
    "    #dataset = data[:,1:]\n",
    "    X_full = (data[:,1:]).T\n",
    "    X_full.shape\n",
    "    #labels = np.reshape(labels,(-1,1))\n",
    "    #labels = labels.T\n",
    "    m = labels.shape[1]\n",
    "    Y = np.zeros((10,m))\n",
    "    for i in range(m):\n",
    "        Y[labels[0,i],i]=1\n",
    "    y_cv = Y[:,0:4000]  \n",
    "    y_test = Y[:,4000:8000]\n",
    "    y_train = Y[:,8000:]\n",
    "    x_cv = X_full[:,0:4000]\n",
    "    x_test = X_full[:,4000:8000]\n",
    "    x_train = X_full[:,8000:]\n",
    "   # print(\"%f %f\" %(y_train.shape[0], y_train.shape[1]))\n",
    "    return x_train,y_train,x_cv,y_cv,x_test,y_test\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_minibatches(X,Y,mb_size,seed):\n",
    "    np.random.seed(seed)\n",
    "    m = X.shape[1]\n",
    "    mini_batches=[]\n",
    "    \n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:,permutation]\n",
    "    shuffled_Y = Y[:,permutation]\n",
    "    mb = mb_size\n",
    "    cmb = math.floor(m/mb)\n",
    "    for i in range(0,cmb):\n",
    "        mini_batch_X = shuffled_X[:,i*mb:(i+1)*mb]\n",
    "        mini_batch_Y = shuffled_Y[:,i*mb:(i+1)*mb]\n",
    "        mini_batch = (mini_batch_X,mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    mini_batch_X = shuffled_X[:,cmb*mb:]\n",
    "    mini_batch_Y = shuffled_Y[:,cmb*mb:]\n",
    "    mini_batch = (mini_batch_X,mini_batch_Y)\n",
    "    mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    parameters={}\n",
    "    np.random.seed(10)\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\"+str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*np.sqrt(2/layer_dims[l-1])\n",
    "        parameters[\"b\"+str(l)] = np.zeros((layer_dims[l],1))\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :\n",
    "    \n",
    "    \n",
    "    L = len(parameters) // 2 \n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "   \n",
    "    for l in range(L):\n",
    "   \n",
    "        v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\"+str(l+1)].shape)\n",
    "        v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\"+str(l+1)].shape)\n",
    "        s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\"+str(l+1)].shape)\n",
    "        s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\"+str(l+1)].shape)\n",
    "\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev,W,b):\n",
    "    cache = (A_prev,W,b)\n",
    "    Z = np.dot(W,A_prev)+b\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev,W,b,activation):\n",
    "    Z,linear_cache = linear_forward(A_prev,W,b)\n",
    "    assert(activation==\"relu\")\n",
    "    A,activation_cache = relu(Z)\n",
    "    cache = (linear_cache,activation_cache)\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X,parameters):\n",
    "    caches=[]\n",
    "    A = X\n",
    "    L = len(parameters)//2\n",
    "    for l in range(1,L):\n",
    "        A_prev = A\n",
    "        A,cache = linear_activation_forward(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"relu\")\n",
    "        caches.append(cache)\n",
    "    ZL =np.dot(parameters[\"W\"+str(L)],A)+parameters[\"b\"+str(L)]\n",
    "    caches.append(((A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)]),(None,None)))\n",
    "    AL = softmax_forward(ZL)\n",
    "    return AL,caches\n",
    "    #TODO: Look up and work out forward prop and backprop for softmax regressison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_forward(Z):\n",
    "    f= np.amax(Z,axis=0)\n",
    "    f = np.array(f)\n",
    "    f = np.reshape(f,(1,f.shape[0]))\n",
    "    Z = Z - f\n",
    "    T = np.exp(Z)\n",
    "    A = T/(np.sum(T,axis=0,keepdims=True)+10**-18)\n",
    "    assert(A.shape==Z.shape)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 9.52574127e-001, 1.00000000e+000,\n",
       "        1.23394576e-004],\n",
       "       [1.39942591e-130, 4.74258732e-002, 5.38018616e-032,\n",
       "        9.99876605e-001]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[500,200,102,36],[201,197,30,45]])\n",
    "softmax_forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y,y_hat):\n",
    "    m = y.shape[1]\n",
    "    cost = -np.sum(y*np.log(y_hat+10**-10)+(1-y)*np.log(1-y_hat+10**-10))/m\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ,cache):\n",
    "    A_prev,W,b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = np.dot(dZ,A_prev.T)/m\n",
    "    db = np.sum(dZ,axis=1,keepdims=True)/m\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dW, db, dA_prev\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA,activation_cache):\n",
    "    Z = activation_cache\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z<=0]=0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA,cache):\n",
    "    linear_cache,activation_cache=cache\n",
    "    dZ = relu_backward(dA,activation_cache)\n",
    "    dW,db,dA_prev = linear_backward(dZ,linear_cache)\n",
    "    return dW,db,dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL,Y,caches):\n",
    "    L = len(caches)\n",
    "    grads={}\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    m = AL.shape[1]\n",
    "    dZL = AL - Y\n",
    "    lincache,_=caches[L-1]\n",
    "    dW,db,dA = linear_backward(dZL,lincache)\n",
    "    grads[\"dW\"+str(L)],grads[\"db\"+str(L)],grads[\"dA\"+str(L-1)] = dW,db,dA\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        grads[\"dW\"+str(l+1)],grads[\"db\"+str(l+1)],grads[\"dA\"+str(l)] = linear_activation_backward(grads[\"dA\"+str(l+1)],current_cache)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads,learning_rate=0.001):\n",
    "    L = len(parameters)//2\n",
    "    for l in range(1,L+1):\n",
    "        parameters[\"W\"+str(l)] -= learning_rate*grads[\"dW\"+str(l)]\n",
    "        parameters[\"b\"+str(l)] -= learning_rate*grads[\"db\"+str(l)]\n",
    "    return parameters\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8,lambd=0.4,m=128):\n",
    "   \n",
    "    \n",
    "    L = len(parameters) // 2                 \n",
    "    v_corrected = {}                        \n",
    "    s_corrected = {}                         \n",
    "    \n",
    "    \n",
    "    for l in range(L):\n",
    "\n",
    "        v[\"dW\" + str(l+1)] = beta1*v[\"dW\"+str(l+1)] + (1-beta1)*grads[\"dW\"+str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1*v[\"db\"+str(l+1)] + (1-beta1)*grads[\"db\"+str(l+1)]\n",
    "\n",
    "\n",
    "\n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\"+str(l+1)]/(1-beta1**(l+1))\n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\"+str(l+1)]/(1-beta1**(l+1))\n",
    "\n",
    "\n",
    "\n",
    "        s[\"dW\" + str(l+1)] = beta2*s[\"dW\"+str(l+1)] + (1-beta2)*grads[\"dW\"+str(l+1)]**2\n",
    "        s[\"db\" + str(l+1)] = beta2*s[\"db\"+str(l+1)] + (1-beta2)*grads[\"db\"+str(l+1)]**2\n",
    "\n",
    "\n",
    "\n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\"+str(l+1)]/(1-beta2**(l+1))\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\"+str(l+1)]/(1-beta2**(l+1))\n",
    "\n",
    "\n",
    "\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*v_corrected[\"dW\" + str(l+1)]/(np.sqrt(s_corrected[\"dW\" + str(l+1)])+epsilon)\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*v_corrected[\"db\" + str(l+1)]/(np.sqrt(s_corrected[\"db\" + str(l+1)])+epsilon)\n",
    "        parameters[\"W\"+str(l+1)] -= ((learning_rate*lambd)/m)*parameters[\"W\"+str(l+1)] \n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model_mb(X,Y,layer_dims, mb=64,learning_rate=0.01,epochs = 500,beta1=0.9,beta2=0.999,epsilon=1e-8):\n",
    "    costs=[]\n",
    "    m = Y.shape[1]\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    v,s = initialize_adam(parameters)\n",
    "    seed = 10\n",
    "    t = 0\n",
    "    for i in range (epochs):\n",
    "        minibatches = random_minibatches(X,Y,mb,seed)\n",
    "        seed=seed+1\n",
    "        cost_total=0\n",
    "        for minibatch in minibatches:\n",
    "            x,y = minibatch\n",
    "            yh,caches = L_model_forward(x,parameters)\n",
    "            cost_total += compute_cost(y,yh)\n",
    "            grads = L_model_backward(yh,y,caches)\n",
    "            t = t + 1\n",
    "            parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,t, learning_rate, beta1, beta2,  epsilon)\n",
    "            #parameters = update_parameters(parameters,grads)\n",
    "            \n",
    "        cost_avg = cost_total/m\n",
    "        if i%100 == 0:\n",
    "            print(\"Cost after %i:%f\" %(i,cost_avg))\n",
    "        if i%100 == 0:\n",
    "            costs.append(cost_avg)\n",
    "    \n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9a40b379906c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,y,parameters):\n",
    "    yh,_ = L_model_forward(x,parameters)\n",
    "    m = yh.shape[1]\n",
    "    predictions = np.argmax(yh,axis=0)\n",
    "    actual = np.argmax(y,axis=0)\n",
    "    correct = 0\n",
    "    for i in range(yh.shape[1]):\n",
    "        if predictions[i] == actual[i]:\n",
    "            correct = correct + 1\n",
    "    return correct/m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0 ,0, 0],[0, 1, 0],[0, 0, 1]])\n",
    "np.argmax(x,axis=0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application():\n",
    "    x_train,y_train,x_cv,y_cv,x_test,y_test = read_data()\n",
    "    layer_dims = [784, 100, 100, 50, 50, 10]\n",
    "    parameters = deep_model_mb(x_train,y_train,layer_dims)\n",
    "    acctrain = predict(x_train,y_train,parameters)\n",
    "    accvalid = predict(x_cv,y_cv,parameters)\n",
    "    acctest = predict(x_test,y_test,parameters)\n",
    "    print(\"Accuracy on trainset: %f\" %(acctrain))\n",
    "    print(\"Accuracy on cross-validation set: %f\" %(accvalid))\n",
    "    print(\"Accuracy on test set: %f\" %(acctest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0:0.039985\n"
     ]
    }
   ],
   "source": [
    "application()\n",
    "#TODO: CREATE WAY TO STORE PARAMETERS IN FILE AND RETRIEVE ACCORDINGLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
